{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "12d9b170-037d-480f-b810-b026ed11f32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "#from langchain.llms import OpenAI\n",
    "from langchain import HuggingFaceHub\n",
    "from langchain import PromptTemplate, OpenAI, LLMChain\n",
    "from langchain.chains import LLMChain, SimpleSequentialChain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95384907-e08d-4919-b47a-45db050bc209",
   "metadata": {},
   "source": [
    "\n",
    "### Comom parameters\n",
    "\n",
    "When using both OpenAI and Google models, there is a parameter called \"temperature,\" which is, in a way, related to the creativity of the response. The value of \"temperature\" ranges from 0 to 1. The lower the value, the more deterministic and predictable the response will be. Conversely, the higher the value, the more creative and surprising the response can be.\r\n",
    "### API Keys\n",
    "\n",
    "To function properly, both the Google and OpenAI models require specific API keys. These API keys are essential for accessing the models' features and have been set up as environment variables. For the Google model, the key is named HUGGINGFACEHUB_API_TOKEN, and for the OpenAI model, the key is termed OPENAI_API_KEY.\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0358a351-8d8b-4ee0-996c-d23eecfaa0f6",
   "metadata": {},
   "source": [
    "## Load API Keys as env variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e2800bf4-eb8f-42dc-a899-dec261b0d3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "HUGGINGFACEHUB_API_TOKEN = os.getenv('HUGGINGFACEHUB_API_TOKEN')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069dd906-3e70-4068-b9c8-ce4f176f5640",
   "metadata": {},
   "source": [
    "# 1. Generating results from an LLM based on Open AI Chat GPT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27803d1-c1c2-4ede-8842-f0d69be9fb00",
   "metadata": {},
   "source": [
    "#### In the example below, we will generate just one result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cd22c849-8352-40bf-974b-a8dc4cc9b53c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\"Rainbow Socks Co.\"\n"
     ]
    }
   ],
   "source": [
    "llm_openai = OpenAI(temperature = 0.85)\n",
    "prompt = \"What would a good company name for be a company that makes colorful socks?\"\n",
    "print(llm_openai(prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de886373-4ef1-4dc4-8aa9-13f0d7ebdbdc",
   "metadata": {},
   "source": [
    "#### In the exemple below, er will generate 5 differents results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1cc2262c-1bb5-49a0-88a7-c29a0878a45c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\"Rainbow Toes Co.\"\n",
      "\n",
      "\n",
      "Rainbow Socks Co. \n",
      " \n",
      "\n",
      "Rainbow Socks Co. \n",
      "\n",
      "RainbowFootwear\n",
      "\n",
      "\n",
      "\"Rainbow Socks Co.\"\n"
     ]
    }
   ],
   "source": [
    "result = llm_openai.generate([prompt]*5)\n",
    "for company_name in result.generations:\n",
    "    print(company_name[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29412f74-b61c-448b-a035-3d653f3501b7",
   "metadata": {},
   "source": [
    "# 2. Generating results from an LLM based on Google"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c057744f-3915-43de-8bb6-ba916ea6729e",
   "metadata": {},
   "source": [
    "In the following example, we are utilizing the 'google/flan-t5-base' model, which is available in the Hugging Face library. It's crucial to clarify that the chosen model is merely for illustrative purposes. Alternatively, we could employ other models such as 'bert-base-uncased', 'gpt-2', 'roberta-large', or 'distilbert-base-uncased'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c9b2e558-b4e4-41b2-83dc-a4a8ab7b8c52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exercise for at least 30 minutes a day.\n"
     ]
    }
   ],
   "source": [
    "llm_google = HuggingFaceHub(repo_id=\"google/flan-t5-base\", \n",
    "                            model_kwargs={\"temperature\":0, \"max_length\":64})\n",
    "prompt = \"What are good fitness tips?\"\n",
    "print(llm_google(prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a55e2a6d-9b9b-4ae9-a47f-aed6a32dcb8c",
   "metadata": {},
   "source": [
    "# 3. Prompt Templating and Chaining\n",
    "\n",
    "Below, we feature a snippet of code that establishes a prompt template for a consultant specializing in devising names for new businesses. The purpose of this prompt is to enable it to suggest an array of business name options adaptable to any specified type of product.\n",
    "\r\n",
    "\r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "360c075f-8b1a-4f92-b54d-5059694464ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"You are a namining consultant for new companies. What is a good name for a {company} that makes {product}?\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "llm_prompt = OpenAI(temperature=0.9)\n",
    "\n",
    "chain = LLMChain(llm = llm_prompt, prompt = prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c2ad02ac-93aa-4db3-bd3e-2a63163594b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\"Vibrant Sox Co.\"\n"
     ]
    }
   ],
   "source": [
    "print(chain.run({\"company\":\"ABC Startup\", \"product\": \"colorful socks\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2162582-cedc-452b-bc30-1daca1acb6ae",
   "metadata": {},
   "source": [
    "### 3.1 - Simple Sequential Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c017d61d-a5cc-4fdc-bd33-79393b3914f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\"Rainbow Threads\" or \"Vibrant Soles\"\n"
     ]
    }
   ],
   "source": [
    "llm_simple_sequential_chain = OpenAI(temperature = 0)\n",
    "template = \"What is a good name for a company that makes {product}\"\n",
    "first_prompt = PromptTemplate.from_template(template)\n",
    "first_chain = LLMChain(llm=llm_simple_sequential_chain, prompt = first_prompt)\n",
    "\n",
    "print(first_chain.run(\"colorful socks\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c94147cd-9651-461a-9676-1ec8db95fe4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "second_template = \"Write a catch phrase for the following company: {company_name}\"\n",
    "second_prompt = PromptTemplate.from_template(second_template)\n",
    "second_chain = LLMChain(llm=llm_simple_sequential_chain, prompt = second_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f72dc732-1448-412c-879e-07b6f3698c62",
   "metadata": {},
   "source": [
    "#### 3.1.1 - Now, we have two chains. The first generates a company name suggestion, and the second creates a slogan. By employing a simple sequential chain, we can use the output of the first chain as the input for the second.\n",
    "\n",
    "In the provided example, we have just two sequential chains, but envision the myriad possibilities when chaining multiple prompts towards a specific goal.\n",
    "\n",
    "In the example below, we initiate a sequential chain where the product name intended for sale is given as input. Based on the product name, the Large Language Model suggests a company name, and then, drawing from the suggested company name, it proposes two slogans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b3d43984-05e3-4277-bb86-84ef0dd38c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_chain = SimpleSequentialChain(chains=[first_chain, second_chain], verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6e6a186e-b2a5-4929-99a5-1f410f8fe1ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3m\n",
      "\n",
      "\"Rainbow Threads\" or \"Vibrant Soles\"\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3m\n",
      "\n",
      "\"Color your world with Rainbow Threads\" \n",
      "\"Step into style with Vibrant Soles\"\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "catchphrase = overall_chain.run(\"colorfull socks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70094987-4063-4e40-bf39-5a4966d5e803",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
